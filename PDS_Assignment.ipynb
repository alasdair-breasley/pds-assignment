{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDS Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/jupyterhub/COMP42315/lib/python3.8/site-packages/urllib3/connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'sitescrape.awh.durham.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Link for website main page\n",
    "main_page_url = \"https://sitescrape.awh.durham.ac.uk/comp42315/\"\n",
    "\n",
    "# Start on main page because first page of publications url might change if new topic of research alphabetically \n",
    "# before \"Animation and Graphics\" is added in the future. More robust to start from main page and find the provided \n",
    "# publications link from there. \n",
    "page = requests.get(main_page_url, verify = False)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"publicationfull_type_animationandgraphics.htm\"><span>PUBLICATIONS</span><span>to innovate</span></a>\n",
      "<class 'str'>\n",
      "publicationfull_type_animationandgraphics.htm\n"
     ]
    }
   ],
   "source": [
    "# Finds all the <a> tags which contain \"publicationfull_type_\" in the href. This start of the relative file path is \n",
    "# the same for all topics in the various publication topic pages and the href for this tag will give the first topic \n",
    "# page alphabetically to start scraping from. \n",
    "publication_navigation_option = soup.find_all(name = \"a\", href = lambda href: href and \"publicationfull_type_\" in href)\n",
    "\n",
    "# Select the one element of the publication_navigation_option list\n",
    "publication_navigation_option = publication_navigation_option[0]\n",
    "\n",
    "print(publication_navigation_option)\n",
    "\n",
    "publication_navigation_relative_url = publication_navigation_option.get(\"href\")\n",
    "\n",
    "print(type(publication_navigation_relative_url))\n",
    "print(publication_navigation_relative_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/jupyterhub/COMP42315/lib/python3.8/site-packages/urllib3/connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'sitescrape.awh.durham.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Concatinate main page url (global) and publication partial url (relative) to get global url for publications page\n",
    "publication_navigation_full_url = main_page_url + publication_navigation_relative_url\n",
    "\n",
    "page = requests.get(publication_navigation_full_url, verify = False)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"publicationfull_type_animationandgraphics.htm\"><span>PUBLICATIONS</span><span>to innovate</span></a>\n",
      "<a href=\"publicationfull_type_movementevaluation.htm\">Movement Evaluation</a>\n",
      "<a href=\"publicationfull_type_biomedicalengineering.htm\">Biomedical Engineering</a>\n",
      "<a href=\"publicationfull_type_interactionmodelling.htm\">Interaction Modelling</a>\n",
      "<a href=\"publicationfull_type_others.htm\">Others</a>\n",
      "<a href=\"publicationfull_type_actionrecognition.htm\">Action Recognition</a>\n",
      "<a href=\"publicationfull_type_depthand3destimation.htm\">Depth and 3D Estimation</a>\n",
      "<a href=\"publicationfull_type_virtualreality.htm\">Virtual Reality</a>\n",
      "<a href=\"publicationfull_type_facialfeatureanalysis.htm\">Facial Feature Analysis</a>\n",
      "<a href=\"publicationfull_type_3dsurfaces.htm\">3D Surfaces</a>\n",
      "<a href=\"publicationfull_type_crowdsimulation.htm\">Crowd Simulation</a>\n",
      "<a href=\"publicationfull_type_robotics.htm\">Robotics</a>\n",
      "<a href=\"publicationfull_type_handmodelling.htm\">Hand Modelling</a>\n",
      "<a href=\"publicationfull_type_computationalintelligence.htm\">Computational Intelligence</a>\n",
      "<a href=\"publicationfull_type_biometrics.htm\">Biometrics</a>\n",
      "<a href=\"publicationfull_type_environmentcapturing.htm\">Environment Capturing</a>\n",
      "<a href=\"publicationfull_type_motionanalysis.htm\">Motion Analysis</a>\n",
      "<a href=\"publicationfull_type_literaturereview.htm\">Literature Review</a>\n"
     ]
    }
   ],
   "source": [
    "# Find all links in the publications page which follow the topic page format \n",
    "publication_page_elements = soup.find_all(name = \"a\", href = lambda href: href and \"publicationfull_type_\" in href)\n",
    "\n",
    "publication_page_urls = []\n",
    "\n",
    "for element in publication_page_elements:\n",
    "    \n",
    "    publication_page_urls.append(element.get(\"href\"))\n",
    "    \n",
    "    print(element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/jupyterhub/COMP42315/lib/python3.8/site-packages/urllib3/connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'sitescrape.awh.durham.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Video-Based Augmented Reality System for Human-in-the-Loop Muscle Strength Assessment of Juvenile DermatomyositisBest Paper Award', 'GAN-based Reactive Motion Synthesis with Class-aware Discriminators for Human-human Interaction', 'Spatio-temporal Manifold Learning for Human Motions via Long-horizon ModelingREF 2021 Submission', 'A Quadruple Diffusion Convolutional Recurrent Network for Human Motion Prediction', 'A Generic Framework for Editing and Synthesizing Multimodal Data with Relative Emotion Strength', 'Multi-layer Lattice Model for Real-Time Dynamic Character Deformation', 'Human Motion Variation Synthesis with Multivariate Gaussian Processes', 'Topology Aware Data-Driven Inverse Kinematics', 'Natural Preparation Behavior Synthesis', 'Simulating Multiple Character Interactions with Collaborative and Adversarial GoalsInvited presentation at ACM I3D 2012 REF 2014 Submission', 'Angular Momentum Guided Motion Concatenation', 'Interaction Patches for Multi-Character AnimationPatent Number: WO/2010/057897 REF 2014 Submission', 'Unifying Human Motion Synthesis and Style Transfer with Denoising Diffusion Probabilistic Models', 'Automatic Sign Dance Synthesis from Gesture-based Sign Language', 'DanceDJ: A 3D Dance Animation Authoring System for Live PerformanceBest Paper Award', 'Synthesizing Motion with Relative Emotion Strength', 'Preparation Behaviour Synthesis with Reinforcement Learning', 'Real-time Physical Modelling of Character Movements with Microsoft Kinect', 'Simulating Interactions of Avatars in High Dimensional State Space', 'Simulating Interactions of Characters', 'Simulating Competitive Interactions using Singly Captured Motions', 'Denoising Diffusion Probabilistic Models for Styled Walking Synthesis', 'Automatic Dance Generation System Considering Sign Language Information', 'Generating Realistic Fighting Scenes by Game Tree', 'Depth Sensor based Facial and Body Animation Control', 'Technical Note: Generating Realistic Fighting Scenes by Game Tree', 'Manufacturing Video Graphics', 'Simulating Interactions Among Multiple Characters']\n",
      "['2023', '2022', '2021', '2021', '2019', '2015', '2014', '2013', '2013', '2012', '2009', '2008', '2023', '2019', '2017', '2017', '2013', '2012', '2008', '2008', '2007', '2022', '2016', '2006', '2016', '2006', '2010', '2010']\n",
      "['Kanglei Zhou, Ruizhi Cai, Yue Ma, Qingqing Tan, Xinning Wang, Jianguo Li, Hubert P. H. Shum, Frederick W. B. Li, Song Jin and Xiaohui Liang', 'Qianhui Men, Hubert P. H. Shum, Edmond S. L. Ho and Howard Leung', 'He Wang, Edmond S. L. Ho, Hubert P. H. Shum and Zhanxing Zhu', 'Qianhui Men, Edmond S. L. Ho, Hubert P. H. Shum and Howard Leung', 'Jacky C. P. Chan, Hubert P. H. Shum, He Wang, Li Yi, Wei Wei and Edmond S. L. Ho', 'Naoya Iwamoto, Hubert P. H. Shum, Longzhi Yang and Shigeo Morishima', 'Liuyang Zhou, Lifeng Shang, Hubert P. H. Shum and Howard Leung', 'Edmond S. L. Ho, Hubert P. H. Shum, Yiu-ming Cheung and P. C. Yuen', 'Hubert P. H. Shum, Ludovic Hoyet, Edmond S. L. Ho, Taku Komura and Franck Multon', 'Hubert P. H. Shum, Taku Komura and Shuntaro Yamazaki', 'Hubert P. H. Shum, Taku Komura and Pranjul Yadav', 'Hubert P. H. Shum, Taku Komura, Masashi Shiraishi and Shuntaro Yamazaki', 'Ziyi Chang, Edmund J. C. Findlay, Haozheng Zhang and Hubert P. H. Shum', 'Naoya Iwamoto, Hubert P. H. Shum, Wakana Asahina and Shigeo Morishima', 'Naoya Iwamoto, Takuya Kato, Hubert P. H. Shum, Ryo Kakitsuka, Kenta Hara and Shigeo Morishima', 'Edmond S. L. Ho, Hubert P. H. Shum, He Wang and Li Yi', 'Hubert P. H. Shum, Ludovic Hoyet, Edmond S. L. Ho, Taku Komura and Franck Multon', 'Hubert P. H. Shum and Edmond S. L. Ho', 'Hubert P. H. Shum, Taku Komura and Shuntaro Yamazaki', 'Taku Komura, Hubert P. H. Shum and Edmond S. L. Ho', 'Hubert P. H. Shum, Taku Komura and Shuntaro Yamazaki', 'Edmund Findlay, Haozheng Zhang, Ziyi Chang and Hubert P. H. Shum', 'Wakana Asahina, Naoya Iwamoto, Hubert P. H. Shum and Shigeo Morishima', 'Hubert P. H. Shum and Taku Komura', 'Yijun Shen, Jingtian Zhang, Longzhi Yang and Hubert P. H. Shum', 'Hubert P. H. Shum and Taku Komura', 'Taku Komura and Hubert P. H. Shum', 'Hubert P. H. Shum']\n"
     ]
    }
   ],
   "source": [
    "# Loop through all topic pages in publications and scrape \n",
    "\n",
    "publication_page_urls = publication_page_urls[0:1]\n",
    "\n",
    "for topic_relative_url in publication_page_urls:\n",
    "    \n",
    "    topic_global_url = main_page_url + topic_relative_url\n",
    "    \n",
    "    page = requests.get(topic_global_url, verify = False)\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    publications = soup.find_all(name = \"div\", class_ = \"w3-cell-row\")\n",
    "    \n",
    "    publication_titles = []\n",
    "    \n",
    "    publication_years = []\n",
    "    \n",
    "    publication_authors = []\n",
    "    \n",
    "    for publication in publications:\n",
    "        \n",
    "        publication_title = publication.find_all(name = \"span\", class_ = \"PublicationTitle\")\n",
    "        \n",
    "        if (len(publication_title)) == 0:\n",
    "            \n",
    "            print(\"Error: Publication element has no title. Please investigate!\")\n",
    "            \n",
    "        elif (len(publication_title)) > 1:\n",
    "                \n",
    "            print(\"Error: Publication element has more than one title. Please investigate!\")\n",
    "                \n",
    "        else:\n",
    "                \n",
    "            publication_titles.append(publication_title[0].text)\n",
    "            \n",
    "        #######\n",
    "            \n",
    "        publication_TextSmalls = publication.find_all(name = \"span\", class_ = \"TextSmall\")\n",
    "        \n",
    "        if (len(publication_TextSmalls)) < 3:\n",
    "            \n",
    "            print(\"Error: Publication element has less tags of TextSmall class than anticipated. Please investigate!\")\n",
    "            \n",
    "        elif (len(publication_title)) > 3:\n",
    "                \n",
    "            print(\"Error: Publication element has more tags of TextSmall class than anticipated. Please investigate!\")\n",
    "                \n",
    "        else:\n",
    "                \n",
    "            publication_years.append(publication_TextSmalls[0].text.rstrip()[-4:])\n",
    "            \n",
    "            publication_authors.append(publication_TextSmalls[1].text)\n",
    "    \n",
    "    print(publication_titles)\n",
    "    print(publication_years)\n",
    "    print(publication_authors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
